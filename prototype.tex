\chapter{Prototype Solution}
\label{chapter:prototype}

In Section \ref{sec:benchmarking} existing solutions for the problems of
publishing, sharing and managin research data were presented. It is clear that
since these solutions exist, there is no point in reinventing the wheel and
implement a new system. Instead we decided to implement a local installation
of some of the systems presented in the benchmarking section. From the test
installations we would choose the one that worked the best and use that to
run tests on potential users of the system. This way we would get insights
going forward on what the finalized system would look like. It's also notable
that the existing solutions are remarkably similar, so using any one of them
would give appliccable results.

The prototype solution focuses on publishing and sharing of research data. The
other option would have been to focus on the research data management during
the research project, but research projects last longer than the span of this
thesis and the results gained from that would likely be quite superficial.
The lack of culture and practices are a factor for both publishing and
and managing research data. The lacking of research data management culture is
due to the lack of education and need for it, whereas publishing research data
is a moderately new phenomenon. This makes it also a more interesting subject
of study.

We ended up choosing the Harvard Dataverse solution to be the prototype for our
purposes. The follwing sections detail the rationale behind this choice, the
technical details of the system and the tests that were conducted using the
system along with the learnings.

\section{Rationale behind selecting Dataverse}

As a part of the benchmarking the existing solutions and in order to select the
we right tool to run tests on users tried installations of a Hydra head, a
Zenodo instance and a Harvard Dataverse instance. These three were chosen
because they represent different technologies and are widely adopted as tools
for publishing research data.

\subsection{Hydra head installation}

Setting up a Hydra head is fairly simple using Ruby
Gems\footnote{\url{https://github.com/projecthydra/hydra-head}}.
Setting up the basic Hydra head
does not get you far, however, since after setting up the installation you need
to define your data model and almost everything else on your repository.

This setup cost makes Hydra a very versatile framework. It's being used on many
places beyond just research institutions, such as museums and image
repositories\footnote{\url{https://wiki.duraspace.org/display/hydra/Partners+and+Implementations}}.
Many of these systems are built on Hydra solution
bundles\footnote{\url{https://wiki.duraspace.org/display/hydra/Hydra+Solution+Bundles}}
which are also
are open source. Installations of a clean Hydra head and the version
run by Penn State University\footnote{\url{https://scholarsphere.psu.edu/}} were tried.

The conclusion about Hydra heads was that while the system is modern and quite
easy to install, the setup of the system made it too time consuming to setup a
testing prototype in a reasonable time frame. The system is flexible and if you
wanted to build your own customized repository solution Hydra would be suitable
for that. The Penn State implementation was heavily branded and tweaked for
their purposes, making it hard to make it work for ptototyping purposes.
Blacklight\footnote{\url{http://projectblacklight.org/}},
the frontend library used by the Hydra
project, is quite good and makes for easy to use and efficient frontends.

\subsection{Zenodo installation}

We tried installing Zenodo system locally from the source
code\footnote{\url{https://github.com/zenodo/zenodo}}, but could not get the
build process to work correclty as of writing of this thesis.
It was later found out that the Zenodo system, which is built upon the Invenio
archiving software, is notoriously hard to install according to the people who
originally built it\footnote{M. Nurmela and D. Lecarpentier, personal
communication, September 30th, 2015}.

Due to the problems with the installation we ruled the Zenodo system out at
the prototyping phase.

\subsection{Harvard Dataverse}

Harvard Dataverse was easy to install with the installation instructions as
both a development version from the source
code\footnote{\url{http://guides.dataverse.org/en/latest/developers/index.html}} and a
production version with
the installation bundle\footnote{\url{http://guides.dataverse.org/en/latest/installation/}}.

The easy installation immediately gave a functioning software repository to
conduct tests with and that lead to the decision to use Dataverse as the
prototype to test current data repository solutions and gain feedback to plan
ahead.

\subsection{Similarity of the existing solutions}

Though implemented in different technologies, the functioning of the existing
research data repository systems is quite similar. All of them offer form based
dataset uploads, full text searches and some forms of access control. Many of
them are even built on same technologies, such as Solr indexing
software\footnote{\label{solr}\url{http://lucene.apache.org/solr/}} or
postgreSQL\footnote{\label{postgre}\url{http://www.postgresql.org/}}.

The similarity of the systems as well as the fact that there is no global
consensus on what repository software is the best in business hints that you
could use any one of them in your organization. From this angle it also makes
sense to use one of them to gain user insights and figure out how the systems
should be developed in order to gain more users for them.

\section{Users of the system}
\label{sec:users}

As examined in Section \ref{chapter:positioning}, a research data repository
systems have many stakeholders. Identified key stakeholders are presented in
the following:

\begin{itemize}
    \item Research scientists
    \item University courses
    \item Research groups
    \item Librarians
    \item Students
    \item IT staff
    \item Other interested parties
\end{itemize}

The requirements of these different stakeholders were boiled down to user
stories, which are presented in Appendix \ref{chapter:first-appendix}.

\section{System description}
\label{sec:system_description}

Harvard Dataverse is a Java application. Other technologies employed are Apache
Solr\footnotemark[\getrefnumber{solr}] for indexing the database to facilitate search,
postgreSQL\footnotemark[\getrefnumber{postgre}] for database
and Glassfish or Apache for serving the
webpages\footnote{\url{https://glassfish.java.net/}, \url{https://httpd.apache.org/}}.
Dataverse also has in built support for the R statistical computing
language\footnote{\url{https://www.r-project.org/}} for running simple
statistical analyses on the data and for data visualization using the
TwoRavens tool \cite{DBLP:conf/ht/HonakerD14}.

The class model of
Dataverse\footnote{\label{architecture}\url{https://github.com/IQSS/dataverse/tree/4.3/doc/Architecture}}
is described in Figure \ref{fig:dataverse-model}.

\begin{figure}
    \begin{centering}
        \includegraphics[width=\textwidth]{images/dataverse-model}
    \end{centering}
    \caption[The Dataverse class model]{The Dataverse class model\footnotemark[\getrefnumber{architecture}]}
    \label{fig:dataverse-model}
\end{figure}

In the heart of Dataverse is the division of content into Dataverses. The
closest analogue to a Dataverse is a normal folder in a typical file system -
Dataverses can contain other Dataverses, but in the place of files Datavereses
contain Datasets. Datasets, in turn, contain the files that make up the
dataset. The Dataverse split of the system also allows for fine grained access
control, since Datavereses can be shared with no one, with single users or user
groups.

Users, other than the administrators of the Dataverse, can use the Dataverse
with either the web user interface or the API offered by Dataverse. The
dataflow of using the Dataverse application\footnotemark[\getrefnumber{architecture}] is shown in Figure
\ref{fig:dataflow}.

\begin{figure}
    \begin{centering}
        \includegraphics[width=\textwidth]{images/dataflow}
    \end{centering}
    \caption[The Dataverse application dataflow]{The Dataverse application dataflow\footnotemark[\getrefnumber{architecture}]}
    \label{fig:dataflow}
\end{figure}

The Dataverse Java application encompasses the Client Side and Dataverse
Application in Figure \ref{fig:dataflow}. Ingest referers to uploading datasets
to the system and the Index and Search and Data/Service components serve the
user the desired content, be it search results or data to be downloaded. The
rApache component handles the data visualization and runs the TwoRavens tool,
and RServe is used for the statistical computation what the system does.

Two versions of the Dataverse system were installed - one from source
code\footnote{\url{https://github.com/quarian/dataverse}} and one from the
installation bundle provided by the developers of
Dataverse\footnote{\url{https://github.com/IQSS/dataverse/releases/tag/v4.2}}.
The installations were run in the CSC cPouta
environment\footnote{\url{https://research.csc.fi/cpouta}}, which is an
OpenStack instance\footnote{\url{https://www.openstack.org/}}. The source code
installation is referenced from now as the development installation since it
was used to get a feel of the code and the system quality and with the access
to the code if weird situations would come up they could be debugging easier.
The installation from the installation bundle is referred to as the production
installation, since it should be more stable than the branch of development
code that was forked for the development installation. Figure
\ref{fig:cpouta} shows the different installations in the cPouta environment.

\begin{figure}
    \begin{centering}
        \includegraphics[width=\textwidth]{images/cpouta}
    \end{centering}
    \caption{The different installations in the cPouta environment}
    \label{fig:cpouta}
\end{figure}

The development installation was installed on top of Ubuntu 14.04 and it
worked, even though the installation instrcutions propose the use of Red Hat
based systems. The TwoRavens application was omitted from the development
installation, since the data visualization is not the core functionality of
the reserach data repository software. The production installation was done
on CentOS 6.6, which is a deriavative of Red Hat Linux. The installation was
first tried on CentOS 7.0, but the differences between CentOS 6.x and 7.x made
it so that the installation would not work.

As for the information security of the prototype solution, the development
installation was not set up with any firewall rules or other security, since
its purpose was to get a feel of the system. For the production installation
firewall rules were set using the security groups functions of OpenStack.
When it comes to research data, security is important, and since the
technologies such as Glassfish and postgreSQL are well known software and
their default passwords and ports are well known setting up firewalls and
chanfing those passwords is imperative. Additionally, with Dataverse,
firewalling the port that Apache Solr uses is important, since it circumvents
the user credentials and it could be used to retrieve any indexed information
in the system.

\section{System testing}
\label{sec:system_testing}

Two folded testing - the pilot users that use the system on their own and give
feedback after using them. Then there are the user tests, which are run under
observation to gauge more insights and see things that the users themselves
might be blind to.

\section{Outcomes of the prototype}
\label{sec:prototype_outcomes}

\begin{itemize}
    \item The manual uploading process is just fine
    \item It is a must that there is an API - for example, thousands of video
          files will not be uploaded manually
    \item It is important that the server can cache large files as a part of
          the upload process
    \item Search functionality
        \begin{itemize}
            \item Poorly described datasets
            \item Not intuitive to find data from within all the search results
            \item Dataset size is no available as a search filtering parameter
            \item The vocabulary in advanced search is foreign for the users
            \item The search results are not well organized
        \end{itemize}
    \item Access controls are important and function quite well
    \item Peer to peer teaching would be good
    \item How data is stored (folder structures and such) contains information
          and that should be captured by the system
    \item Accessing data from outside work computers would be nice
    \item More to come here, have to dig up my notes
\end{itemize}
