\chapter{Discussion}
\label{chapter:discussion}

\section{Methods}

In this thesis we have examined the challenges around research data management,
sharing and publishing. The methods used are literature reviews,
interviews, questionnaires, technical benchmarks and user tests in the form of contextual
interviews and lead user tests.

Literature reviews on the subject show that while the open access way of
publishing research papers has been studied, the scientific contribution to
the problem of open access research data has been tackled by a small number
of researchers. Statistical studies of open access benefits with research
papers promise good results for publishing in open access style, but the
methodology and sample size quality varies. The metrics and numbers about
research data sharing and management are all different within the research
papers published, making it harder to interpret results from them. This is to
be expected, since research data publication and sharing is a relatively new
phenomenon. A challenge for the future would be to rigorously quantify the
benefits of research data publication and sharing. Not many concrete numbers
about the benefits of research data publishing and sharing are found from the
literature. Many of the research papers
in the field are also quite new, so it will take time to find out which ones
of them provide to be the most valuable.

Interviews were used to find out the current situation of research data
management and sharing in Finland. The interviewees represented many groups
of stakeholders, but it is possible that the people chosen for the interviews
were not the best representatives of their group. Legal issues were also
brought up quite a few times during this thesis and it would have been
beneficial to interview a legal expert as well. The interviews were conducted
in places chosen by the interviewees to make the interview process easier
for them. One possible problem with the interviews was that they were
conducted alone, but this was taken into account by recording the interviews.
Similar questions were asked from all the interviewees, but with many of them
the deep discussions were done on different topics. Doing more interviews to
gain more data points and following up on the interviewees on later parts
of the research would have been beneficial. The Complex Network group was
interviewed in two phases of the thesis (initial interviews and contextual
interviews in the prototyping phase) and that proved valuable - hinting
that revisiting other interviews would have been valuable as well. Time
constraints of the thesis prevented this.

The questionnaires were not designed for the use of this thesis~\cite{survey1, survey2}. Instead they were used
to find out the research data management needs of Aalto for planning the
future of services offered by Aalto. However, the questions asked in the
surveys were very relevant for this thesis as well which led to the decision
to use them as is instead of doing overlapping work. The general caveats of
surveys, such as the shallowness of information and the chance of
misinterpretation, apply of course. To minimize the the risk of misinformation
the results from the surveys were shown as is and interpretation was kept to a
minimum. Repeating the questionnaires could have been valuable since they were
conducted two years ago. We did not spend resources on this since the deeper user
interview and test feedback was considered higher value.

Technical benchmarking was done with existing solutions to a somewhat varying degree.
The Dataverse solution was inspected thoroughly, Zenodo and Hydra installations were tried,
other publishing platforms were signed up for and tried that way, and iRODS
was studied through the documentation and source code. There is a possibility
that the conclusions drawn from the thorough inspection of Dataverse do not
apply for the other solutions directly, but since the implementations are quite
similar the risk is likely low. We have tried separating the learnings from the
systems from the system specific features, such as the look and feel of their
UIs. The cloud environment that is used as the running environment of the prototype
Dataverse system would not be the installation destination of the final system.
This did not generate problems for the testing of the system. More hands on
testing on the different technical solutions would have been beneficial, but
this was not feasible in the time frame of the thesis.

The contextual interviews and lead user tests were chosen as a tool to learn
more about the research data publication systems to complement the technical
examination. Questionnaires would be another option, but while you could get more data
points from a survey, the information is superficial. One angle for this thesis
is that Aalto University is forming a data policy to to govern research data
management and publishing and gaining deeper user insights through controlled
user tests would provide deeper insights for that as well. Additionally,
surveys on the subject had already been made and they are introduced in
Section \ref{sec:questionnaire}. The sample size
of 12 users (10 for the contextual interviews and 2 for the lead user tests)
does not yield statistically significant results, but the depth that the
examination was carried out with should provide value. Enlisting more lead
users would have been beneficial but we could not find users with enough
time to test the system.

It was interesting that the interactions with the users of the system brought
up similar points that were raised in the literature. The lack of culture and
same reasons for not sharing research data were found out within the users as were
found out in the literature.
The sample size is not, again, scientifically significant, but
it seems likely that the problems reported in literature around the world do
happen in Finland as well.

The goal of combining these methods was to gain a holistic view on the problem
and not only focus on the technological side. More user engagement would have
given a better view, but on the whole we feel that the overall view created by
this thesis is representative of current state of the research data sharing,
publishing and management in the field of science.

The chosen methodologies were chosen also partially to accommodate the studies
of the writer of this thesis - I have studied user centered design as a my
minor during my Masters' studies.

\section{Combining insights}

While the main focus of this thesis from the beginning was to find
appropriate technical solutions for sharing research data it became clear
that sharing research data is not strictly a technical problem. While there is
a lot of work to be done to implement tools and systems to make the process of
sharing and publishing research data easy, a point solution to do just that
would fall flat. Firstly, research data publication and sharing is closely
tied to research data management during the research process. If research data
is not handled during the process with the goal of one day making it public,
the process of eventually making it public is very hard or impossible. And even
though it might be technically viable the time and effort it would take to
turn datasets that have not been properly documented and maintained during the
process might be prohibitive. Secondly, the culture for sharing research data
is still developing. There is not enough knowledge about either research data management
or sharing. Additionally, there is no incentive to share research data, since
researchers' contribution is measured mainly in citation to research papers.

The problem of research data also involves people from different disciplines
in unprecedented ways. The roles of libraries, university software
infrastructure maintainers and the researchers themselves are undefined in
the new world of research data management, publication and sharing. When you
consider the academic publishers and the peer review process that is at the
heart of scientific publishing it is clear that the roles of all
these actors need to be defined in the research data context.

Making research data accessible is likely to promote the quality of science.
To achieve this, better technical solutions need to be implemented and the
culture around research data needs to be taken into a more open direction.

Examining the state and options that come with research data management,
publishing and sharing four survival strategies for the data intensive world
of research can be outlined. The strategies are, in order from the most recommendable
to the least recommendable, international collaboration,
open source solutions, national collaboration and implementing own solutions.

International collaboration entails being a part of a international initiative
for research data management, sharing and publication. EUDAT is an example of
an initiative like this. This makes collaboration with others that are working
in the initiative easier, takes the implementation load off the institutions
while giving them a chance to participate and lessens the amount of existing
systems and standards. The challenge is to adapt the international solutions
to conform to the local needs of research institutions.

Implementing one of the existing open source solutions in a research
institution would bring that institution to the community around that solution.
Example solutions include Dataverse, CKAN and Invenio. The problem with institutions
implementing different open source solutions is that it increases the overall
complexity of the research data landscape and puts the burden of maintaining
the solution to the research institution.

National initiatives, such as the Open Research and Science initiative in Finland,
take the burden of implementation from the research institutions. The problem is that
research nowadays is global and the national providers are likely to enable national
collaboration very well, but international collaboration would be a challenge.

Implementing a novel solution for a research institution is an option, but seems
very inefficient since solutions exist already. While you might get a perfectly
tuned system for your institution, it would be more cost efficient to use existing
solutions. Implementing own solutions also means that the burden to integrate with
other systems is on you.

This thesis has also identified many aspects of a solution that could solve the
research data management, publishing and sharing problems. These aspects are
boiled down to a set of design requirements. The requirements
can be used as a basis to design solutions or as means to validate existing
solutions.

These requirements are split into
must have requirements, functional requirements, hardware requirements and
user experience requirements. Other than the must have requirements that a
system either does or does not fulfill the requirements contain metrics that
can be used to validate if the system fulfills the requirement. The formulation
of the requirements presented here is quite general,
which means that in order to use them to design or validate a solution the metrics
presented in the requirements should be made more specific. The requirements
are also not instructions set in stone - they should be used to guide in
developing a research data management, sharing and publishing system.

The must have requirements are presented in Tables \ref{table:must_have_publishing} and
\ref{table:must_have_management}. The other requirements are presented in Appendix
\ref{chapter:reqs}.

\captionof{table}{Must have requirements for a research data publishing solution}
\addtocounter{table}{-1}
\label{table:must_have_publishing}
    \begin{tabularx}{\textwidth}{| >{\raggedright}p{3cm} | X |}
    \hline
    \textbf{Requirement} & \textbf{Rationale} \\
    \hline
    \rowcolor{Gray}
    Users can upload datasets    & Without datasets, there is not research data publishing\\
    \hline
    User can upload relevant metadata for their datasets & Without metadata, finding and reusing research data is impossible\\
    \hline
    \rowcolor{Gray}
    The metadata of datasets is full text searchable    &  In order to find datasets, the metadata has to be searchable\\
    \hline
    Published datasets are assigned a persistent identifiers    & Persistent identifiers allow for referencing the data and maintaining links for longer\\
    \hline
    \rowcolor{Gray}
    There are no restrictions to the type of uploaded data          & Research data comes in many shapes and forms and all data must be able to be published\\
    \hline
    The datasets in the system can be made public for all the world to see    & The goal of the publishing platform is to make the data public\\
    \hline
\end{tabularx}

\captionof{table}{The must have requirements of a research data management solution}
\addtocounter{table}{-1}
\label{table:must_have_management}
    \begin{tabularx}{\textwidth}{| >{\raggedright}p{3cm} | X |}
    \hline
    \textbf{Requirement} & \textbf{Rationale} \\
    \hline
    \rowcolor{Gray}
    Users can upload their research data during the research project    & Instead of per researcher storage solution for storing research data, there must be a centralized solution\\
    \hline
    The tool imposes no restrictions to the type of research data stored & Research data comes in all shapes and forms and the tool must serve all the disciplines\\
    \hline
    \rowcolor{Gray}
    The research data management tool must allow for sharing data with collaborators    &  Research is done globally and collaboratively nowadays, meaning that data must be shared with collaborators\\
    \hline
\end{tabularx}

\section{Future work}

Future work around the subject should include both integrated
technical solutions that make good research data management practices a part of the
daily life of researchers. This would in turn make the publication of their data easy
and help improving the culture around the subject.
To change the culture more research on the benefits of open research data
is required, but there might be other ways as well.

Some fields of science, such as physics, psychology and genomics have been
more successful than other fields in implementing open research data practices.
Research on how these fields managed that transition and how that could be applied
to other fields could find ways to bring open research data to other
fields as well.

It is also possible that the culture of research data could be changed with
appropriate sticks and carrots. If funding bodies would make it a priority
to demand public research data, there would likely be an urgency to provide
such solutions for researchers as soon as possible. On the other hand, maybe
citations to research data could be integrated to the h-index of researchers,
thus making the already used metric reward those who publish their datasets.
This reframing of the problem - instead of asking ''how should we implement
systems that help with research data?'' we ask ''how do we motivate people
to share their research data'' - is a design paradigm that has been used
successfully in other system level design problems \cite{dorst2015frame}.

The solutions for the technical and cultural problems might also be found
from analogous problems. For example, software development has benefited for
a long time from the open source community, where people contribute code for
the public domain without monetary compensation. It is been studied that people do not
do this out of the kindness of their hearts, but instead with the goal of
turning their free work now into profit in the future
\cite{DBLP:conf/hicss/HarsO01}. The tools that are used to share software,
such as GitHub, could also provide a fresh look on how tools for research
data management and sharing could work.

\iffalse
In this chapter we will discuss the findings, methods and such in a good
scientific manner.

At some point I want to discuss the analogue of software open source community
and how that works - how we should make people proud of making good, usable
datasets and sharing them.

\cite{DBLP:conf/hicss/HarsO01} is about the motivations behind working on open
source software - could be used for analogue for open data.

\cite{dorst2015frame} is the Kees Dorst book about reframing problems, which in
this case would be taking the technical problem of sharing reserch data, which
is not the actual problem, and reframing it as the problem on how to motivat
people to to share their data.
\fi
